# ğŸ§  Ragnify â€“ Offline RAG-based AI Document Assistant

**Ragnify** is a powerful **RAG (Retrieval Augmented Generation)** based offline AI tool built to deliver **accurate, document-grounded answers** from your PDF files. Designed for **complete offline use**, it integrates **OCR capabilities** and **LLM (LLaMA 2 7B GGUF)** models to provide highly relevant, hallucination-free answers.

> ğŸ”§ Developed by **Aryan Singh** and **Bhavya Jain**  
> ğŸ§‘â€ğŸ« Guided by **Mr. Ankit Pratap Sir** during our internship at **Tech Mahindra**  

---

## ğŸ§© Key Features

- ğŸ” **RAG-based Context Retrieval** â€” Ensures answers are backed by the document.
- ğŸ§  **LLaMA 2 Integration (Offline)** â€” Uses 7B GGUF model with no external calls.
- ğŸ“¥ **Multi-PDF Upload** â€” Seamlessly handle multiple documents.
- ğŸ§¾ **OCR Support with Tesseract** â€” Converts scanned or image-based PDFs to text.
- ğŸ” **100% Offline** â€” No data sent to the cloud, perfect for private and secure use.
- ğŸš« **Zero Hallucinations** â€” Model only answers based on available context.
- ğŸ¯ **Fast and Accurate** â€” High performance even on limited hardware.
- ğŸª„ **Minimal UI** â€” Built with Streamlit for simplicity and speed.
- ğŸ› ï¸ **Customizable** â€” Easily adapt to new document sets or other LLMs.

---

## ğŸ” How It Works

1. **PDF Upload**: Users upload one or more PDFs via the Streamlit interface.
2. **OCR Processing**: Tesseract automatically extracts text from scanned/image PDFs.
3. **Chunking**: Documents are broken down into manageable text chunks.
4. **Embedding**: Each chunk is embedded and stored in a **FAISS vector database**.
5. **Query Input**: User asks a question through the UI.
6. **Context Retrieval**: Semantic search fetches relevant chunks.
7. **Answer Generation**: The **LLaMA 2 model** generates an accurate, context-aware answer.

---

## ğŸ§  What is RAG?

**RAG (Retrieval-Augmented Generation)** is an AI technique where external knowledge (PDFs in our case) is retrieved and used to **augment the input to the language model**, ensuring more accurate and grounded responses.

---

## ğŸ—ƒï¸ Project Structure

```bash
Ragnify/
â”œâ”€â”€ app.py                  # Main Streamlit app
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ llm_model/              # Folder for GGUF LLaMA model
â”œâ”€â”€ ocr_utils/              # OCR setup and utilities (Tesseract)
â”œâ”€â”€ utils/                  # PDF processing, chunking, embedding
â”œâ”€â”€ faiss_index/            # Vector store (FAISS)
â”œâ”€â”€ stored_pdfs/            # Uploaded PDF storage
â””â”€â”€ README.md               # You're here!


ğŸ§ª Future Improvements
ğŸŒ Multi-language support for PDFs

â˜ï¸ Optional cloud backup or API-based LLM extensions

ğŸ“Š Visualization support for data-heavy documents (tables, charts)

âš™ï¸ Docker setup for cross-platform ease of deployment

ğŸ”„ Add CSV/Word support in addition to PDF

ğŸ¤– Add voice-based query input and response

ğŸ§¬ Fine-tune LLM for legal, medical, or research domains



ğŸ’¬ Contact
ğŸ“§ Email: aryanmessi03@gmail.com
ğŸ”— LinkedIn: https://www.linkedin.com/in/aryan-singh-b66431244/

